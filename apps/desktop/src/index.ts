// Main process entry point
import { app, BrowserWindow, Tray, Menu, nativeImage, ipcMain, desktopCapturer, session, systemPreferences, shell } from 'electron';
import WebSocket from 'ws';

// This allows TypeScript to pick up the magic constants that's auto-generated by Forge's Webpack
// plugin that tells the Electron app where to look for the Webpack-bundled app code
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
// eslint-disable-next-line @typescript-eslint/no-require-imports
if (require('electron-squirrel-startup')) {
  app.quit();
}

// Type definitions
type AudioCaptureStatus = 'idle' | 'connecting' | 'capturing' | 'error';

interface AudioCaptureConfig {
  callId?: string;
  teamId: string;
  closerId: string;
  prospectName?: string;
}

let mainWindow: BrowserWindow | null = null;
let tray: Tray | null = null;
let isQuitting = false;

// Audio capture state
let audioStatus: AudioCaptureStatus = 'idle';
let wsConnection: WebSocket | null = null;
let currentCallId: string | null = null;

// Audio service URL - Production Railway deployment
const AUDIO_SERVICE_URL = process.env.AUDIO_SERVICE_URL || 'wss://amusing-charm-production.up.railway.app';

const createWindow = (): void => {
  // Create the browser window.
  mainWindow = new BrowserWindow({
    width: 400,
    height: 600,
    minWidth: 350,
    minHeight: 500,
    titleBarStyle: 'hiddenInset',
    backgroundColor: '#000000',
    show: false,
    webPreferences: {
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY,
      nodeIntegration: false,
      contextIsolation: true,
      // Allow loading external scripts (needed for Clerk auth)
      webSecurity: false,
    },
  });

  // Set up display media request handler for system audio capture
  // This is the key to capturing loopback audio on macOS
  session.defaultSession.setDisplayMediaRequestHandler((request, callback) => {
    console.log('[Main] Display media request received');
    desktopCapturer.getSources({ types: ['screen'] }).then((sources) => {
      if (sources.length > 0) {
        console.log('[Main] Providing screen source with loopback audio');
        // Pass the first screen source with loopback audio
        callback({ video: sources[0], audio: 'loopback' });
      } else {
        console.error('[Main] No screen sources available');
        callback({});
      }
    }).catch((err) => {
      console.error('[Main] Error getting sources:', err);
      callback({});
    });
  });

  // Load the index.html of the app.
  mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY);

  // Show window when ready
  mainWindow.once('ready-to-show', () => {
    mainWindow?.show();
  });

  // Prevent window from closing, minimize to tray instead
  mainWindow.on('close', (event) => {
    if (!isQuitting) {
      event.preventDefault();
      mainWindow?.hide();
    }
  });

  // Open DevTools in development
  if (process.env.NODE_ENV === 'development' || process.defaultApp) {
    mainWindow.webContents.openDevTools({ mode: 'detach' });
  }
};

const createTray = (): void => {
  // Create a simple tray icon from a data URL
  const icon = nativeImage.createFromDataURL(
    'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAAbwAAAG8B8aLcQwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAABrSURBVDiNY2AYBQMNGBkZ/1NSUhJhZGT8T4oeFHr+//+vwMDA8B8ZkKIHhYH//xkYGBgYcGkgRQ8KA+kGENKDyw1kA6J9QEgPLjfgBPj0EAXINoCQHqK8QEgPLjeQDXDpIRsQ0kNRiA8lAAApfkE9rChPUQAAAABJRU5ErkJggg=='
  );

  tray = new Tray(icon.resize({ width: 16, height: 16 }));

  const contextMenu = Menu.buildFromTemplate([
    {
      label: 'Show Seq3nce',
      click: () => {
        mainWindow?.show();
        mainWindow?.focus();
      },
    },
    { type: 'separator' },
    {
      label: 'Start Recording',
      click: () => {
        mainWindow?.webContents.send('tray:start-recording');
      },
    },
    {
      label: 'Stop Recording',
      click: () => {
        mainWindow?.webContents.send('tray:stop-recording');
      },
    },
    { type: 'separator' },
    {
      label: 'Quit Seq3nce',
      click: () => {
        isQuitting = true;
        app.quit();
      },
    },
  ]);

  tray.setToolTip('Seq3nce');
  tray.setContextMenu(contextMenu);

  // Double-click to show window
  tray.on('double-click', () => {
    mainWindow?.show();
    mainWindow?.focus();
  });
};

// Update status and notify renderer
const updateStatus = (status: AudioCaptureStatus) => {
  audioStatus = status;
  mainWindow?.webContents.send('audio:status-change', status);
  console.log(`[Main] Audio status: ${status}`);
};

// Connect to WebSocket server
const connectWebSocket = (config: AudioCaptureConfig & { callId: string }): Promise<boolean> => {
  return new Promise((resolve) => {
    console.log(`[Main] Connecting to WebSocket: ${AUDIO_SERVICE_URL}`);

    try {
      wsConnection = new WebSocket(AUDIO_SERVICE_URL);

      const timeout = setTimeout(() => {
        console.error('[Main] WebSocket connection timeout');
        wsConnection?.close();
        resolve(false);
      }, 10000);

      wsConnection.on('open', () => {
        clearTimeout(timeout);
        console.log('[Main] WebSocket connected');

        // Send metadata
        const metadata = {
          callId: config.callId,
          teamId: config.teamId,
          closerId: config.closerId,
          prospectName: config.prospectName,
        };

        wsConnection!.send(JSON.stringify(metadata));
        console.log('[Main] Sent metadata:', metadata);
      });

      wsConnection.on('message', (data) => {
        try {
          const message = JSON.parse(data.toString());
          console.log('[Main] WebSocket message:', message);

          if (message.status === 'ready') {
            console.log('[Main] Server ready, can start streaming');
            resolve(true);
          } else if (message.error) {
            console.error('[Main] Server error:', message.error);
            mainWindow?.webContents.send('audio:error', message.error);
            resolve(false);
          }
        } catch (err) {
          console.error('[Main] Failed to parse message:', err);
        }
      });

      wsConnection.on('error', (err) => {
        clearTimeout(timeout);
        console.error('[Main] WebSocket error:', err);
        mainWindow?.webContents.send('audio:error', `Connection error: ${err.message}`);
        resolve(false);
      });

      wsConnection.on('close', () => {
        console.log('[Main] WebSocket closed');
        if (audioStatus === 'capturing') {
          updateStatus('error');
          mainWindow?.webContents.send('audio:error', 'Connection lost');
        }
        wsConnection = null;
      });
    } catch (err) {
      console.error('[Main] Failed to create WebSocket:', err);
      resolve(false);
    }
  });
};

// Send audio data to WebSocket
const sendAudioData = (data: Buffer) => {
  if (wsConnection && wsConnection.readyState === WebSocket.OPEN) {
    wsConnection.send(data);
  }
};

// Close WebSocket connection
const closeWebSocket = async () => {
  if (wsConnection) {
    if (wsConnection.readyState === WebSocket.OPEN) {
      // Send end message
      wsConnection.send(JSON.stringify({ type: 'end' }));
      // Wait a bit for message to be sent
      await new Promise((resolve) => setTimeout(resolve, 500));
    }
    wsConnection.close();
    wsConnection = null;
  }
};

// Set up IPC handlers
const setupIpcHandlers = (): void => {
  console.log('[Main] Setting up IPC handlers...');

  // Get current audio capture status
  ipcMain.handle('audio:get-status', () => {
    return audioStatus;
  });

  // Check permissions (macOS screen recording)
  // Note: This is unreliable on macOS - 'screen' often shows 'denied' even when granted
  // We'll try to capture anyway and handle errors gracefully
  ipcMain.handle('audio:check-permissions', async () => {
    if (process.platform === 'darwin') {
      const status = systemPreferences.getMediaAccessStatus('screen');
      console.log(`[Main] Screen recording permission status: ${status}`);
      // Return true to allow attempting capture - real check happens in renderer
      // 'not-determined' means user hasn't been asked yet
      return status === 'granted' || status === 'not-determined';
    }
    return true;
  });

  // Request permissions - opens System Preferences on macOS
  ipcMain.handle('audio:request-permissions', async () => {
    if (process.platform === 'darwin') {
      // Open System Preferences to Screen Recording
      shell.openExternal('x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture');
      return false; // User needs to manually grant and restart
    }
    return true;
  });

  // Open system preferences directly
  ipcMain.handle('audio:open-preferences', () => {
    if (process.platform === 'darwin') {
      shell.openExternal('x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture');
    }
  });

  // Start audio capture - returns callId, actual capture happens in renderer
  ipcMain.handle('audio:start', async (_event, config: AudioCaptureConfig) => {
    console.log('[Main] Starting audio capture with config:', config);

    if (!config.teamId || !config.closerId) {
      return { success: false, error: 'Missing teamId or closerId' };
    }

    // Generate call ID if not provided
    const { v4: uuidv4 } = await import('uuid');
    const callId = config.callId || uuidv4();
    currentCallId = callId;

    // Update status to connecting
    updateStatus('connecting');

    // Connect to WebSocket
    const connected = await connectWebSocket({ ...config, callId });

    if (!connected) {
      updateStatus('error');
      return { success: false, error: 'Failed to connect to audio service' };
    }

    // Status will be updated to 'capturing' when renderer starts sending audio
    return { success: true, callId };
  });

  // Receive audio data from renderer and forward to WebSocket
  ipcMain.on('audio:data', (_event, data: ArrayBuffer) => {
    if (audioStatus === 'connecting') {
      // First audio data received, update status
      updateStatus('capturing');
    }

    if (wsConnection && wsConnection.readyState === WebSocket.OPEN) {
      wsConnection.send(Buffer.from(data));
    }
  });

  // Receive audio level from renderer
  ipcMain.on('audio:level', (_event, level: number) => {
    mainWindow?.webContents.send('audio:level', level);
  });

  // Stop audio capture
  ipcMain.handle('audio:stop', async () => {
    console.log('[Main] Stopping audio capture...');

    await closeWebSocket();
    currentCallId = null;
    updateStatus('idle');

    return { success: true };
  });

  // Get app version
  ipcMain.handle('app:get-version', () => {
    // eslint-disable-next-line @typescript-eslint/no-require-imports
    const pkg = require('../package.json');
    return pkg.version;
  });

  // Get platform info
  ipcMain.handle('app:get-platform', () => {
    return {
      platform: process.platform,
      arch: process.arch,
    };
  });

  // Get audio service URL (for debugging)
  ipcMain.handle('audio:get-service-url', () => {
    return AUDIO_SERVICE_URL;
  });

  console.log('[Main] IPC handlers set up');
};

// This method will be called when Electron has finished initialization
app.whenReady().then(() => {
  createWindow();
  createTray();
  setupIpcHandlers();

  app.on('activate', () => {
    if (BrowserWindow.getAllWindows().length === 0) {
      createWindow();
    } else {
      mainWindow?.show();
    }
  });
});

// Quit when all windows are closed, except on macOS
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

// Handle before quit
app.on('before-quit', async () => {
  isQuitting = true;
  await closeWebSocket();
});
